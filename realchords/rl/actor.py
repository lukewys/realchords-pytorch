"""Actor model class for RL training."""

from typing import Optional, Tuple, Union, Dict, Any

import torch
import torch.nn as nn
import torch.distributed as dist
from functools import partial

from realchords.rl.openrlhf_local import Actor, log_probs_from_logits

from realchords.dataset.hooktheory_tokenizer import HooktheoryTokenizer
from realchords.utils.sequence_utils import (
    add_bos_to_sequence,
    add_eos_to_sequence,
)
from realchords.rl.marl_interaction import generate_marl
from realchords.model.sampling import (
    filter_special_token,
    top_k,
    filter_invalid_tokens_generate_online,
)


class ReaLchordsActor(Actor):
    """Base class for ReaLchords actor models."""

    def __init__(
        self,
        model: torch.nn.Module,
        bos_token_id: int,
        eos_token_id: int,
        pad_token_id: int,
        max_seq_len: int,
    ) -> None:
        """Compared to openrlhf Actor class, we remove the following supports and features:

        1. load_in_4bit
        2. lora
        3. moe
        4. ds_config (deepspeed config)
        5. load from huggingface model name (string)
        6. packing samples
        """
        super(Actor, self).__init__()

        self.model = model
        self.bos_token_id = bos_token_id
        self.eos_token_id = eos_token_id
        self.pad_token_id = pad_token_id
        self.max_seq_len = max_seq_len

    @torch.no_grad()
    def generate(
        self, batch: Dict[str, Any], **kwargs
    ) -> Tuple[torch.LongTensor, torch.LongTensor, torch.BoolTensor]:
        """Generate sequences from batch input."""
        raise NotImplementedError

    def create_action_mask_from_sequences(
        self, sequences: torch.Tensor, input_len: int
    ):
        # in RL, state_i (current token) + action_i (next token) -> state_i+1 (next token)
        state_seq = sequences[:, input_len - 1 : -1]
        action_mask = state_seq.ne(self.eos_token_id) & state_seq.ne(
            self.pad_token_id
        )
        action_mask[:, 0] = 1
        return action_mask

    def process_sequences(
        self,
        sequences: torch.Tensor,
        input_len: int,
        **kwargs,
    ):
        raise NotImplementedError

    def forward(
        self,
        sequences: torch.LongTensor,
        num_actions: Optional[Union[int, list[int]]] = None,
        attention_mask: Optional[torch.Tensor] = None,
        return_output: bool = False,
        **kwargs,
    ) -> torch.Tensor:
        """Returns action log probs.

        Compared to the original forward, remove the creation of position_ids.
        """

        logits = self.model(sequences, mask=attention_mask)

        if num_actions is None:
            assert return_output
            return logits

        log_probs = log_probs_from_logits(logits[:, :-1, :], sequences[:, 1:])

        action_log_probs = log_probs[:, -num_actions:]

        logits = logits[:, :-1, :]  # remove the last token logits

        if return_output:
            return (action_log_probs, logits)
        else:
            return action_log_probs


class DecoderSinglePartActor(ReaLchordsActor):
    """Decoder-only transformer generating single part for RL training."""

    def process_sequences(
        self,
        sequences: torch.Tensor,
        input_len: int,
    ):
        """Process generated sequences to generate mask.

        attention_mask: mask for all tokens except padding tokens, including
            context tokens that are not generated by model (prompts).
        action_mask: mask for all tokens that are generated by model.

        Unlike OpenRLHF, we do not add EOS tokens to the sequences.
        """
        attention_mask = sequences.ne(self.pad_token_id)

        action_mask = self.create_action_mask_from_sequences(
            sequences, input_len
        )

        # Different from OpenRLHF, we convert masks to bool tensor for x-transformers
        attention_mask = attention_mask.bool()
        action_mask = action_mask.bool()
        # action_mask: 0 for tokens not generated by model

        return sequences, attention_mask, action_mask

    @torch.no_grad()
    def generate(self, batch: Dict[str, Any], **kwargs) -> Union[
        Tuple[torch.LongTensor, torch.LongTensor],
        Tuple[torch.LongTensor, torch.LongTensor, torch.BoolTensor],
    ]:
        """Generate sequences from batch input."""
        # Here we ignore the contents in batch and perform unconditional generation.
        device = next(self.model.parameters()).device
        input_ids = batch["targets"]
        batch_size = input_ids.size(0)

        gen_inputs = torch.full(
            (batch_size, 1),
            self.bos_token_id,
            dtype=torch.long,
            device=device,
        )

        # Call generate
        sequences = self.model.generate(
            gen_inputs,
            seq_len=self.max_seq_len,
            cache_kv=True,
            eos_token=self.eos_token_id,
        )

        # In x-transformers, output will not contain prompt.
        # However, we need at least the BOS for calculating the log probs.
        # So here we add the prompt to the beginning of the sequences.
        input_len = 1
        sequences = torch.cat([gen_inputs, sequences], dim=1)

        return self.process_sequences(sequences, input_len)


class DecoderSingleAgentActor(ReaLchordsActor):
    """ReaLchords actor.

    Decoder-only transformer generating one part given
        another part as fixed data for RL training."""

    def __init__(
        self,
        model: torch.nn.Module,
        tokenizer: HooktheoryTokenizer,
        max_seq_len: int,
        model_part: str,
    ) -> None:
        """Compared to the base class, we add the tokenizer."""
        # skip the super call, directly call the Actor class's __init__
        super(Actor, self).__init__()

        self.model = model
        self.max_seq_len = max_seq_len
        self.tokenizer = tokenizer
        self.bos_token_id = tokenizer.bos_token
        self.eos_token_id = tokenizer.eos_token
        self.pad_token_id = tokenizer.pad_token
        self.silence_token_id = tokenizer.silence_token
        self.model_part = model_part
        self.init_filter_fn()

    def init_filter_fn(self):
        # self.filter_invalid_tokens_fn = partial(
        #     filter_invalid_tokens_generate_online,
        #     model_part=self.model_part,
        #     tokenizer=self.tokenizer,
        # )
        self.filter_invalid_tokens_fn = partial(top_k, frac_num_tokens=1.0)
        self.default_filter_fn = partial(top_k, frac_num_tokens=1.0)
        # self.default_filter_fn = filter_special_token

    def process_sequences(
        self,
        sequences: torch.Tensor,
        input_len: int,
    ):
        """Process generated sequences to generate mask.

        attention_mask: mask for all tokens except padding tokens, including
            context tokens that are not generated by model (prompts).
        action_mask: mask for all tokens that are generated by model.

        Unlike OpenRLHF, we do not add EOS tokens to the sequences.
        """
        attention_mask = sequences.ne(self.pad_token_id)

        action_mask = self.create_action_mask_from_sequences(
            sequences, input_len
        )

        # Different from OpenRLHF, we convert masks to bool tensor for x-transformers
        attention_mask = attention_mask.bool()
        action_mask = action_mask.bool()
        # action_mask: 0 for tokens not generated by model

        return sequences, attention_mask, action_mask

    @torch.no_grad()
    def generate(
        self, batch: Dict[str, Any], enable_filter_fn: bool = False, **kwargs
    ) -> Tuple[torch.LongTensor, torch.LongTensor, torch.BoolTensor]:
        """Generate sequences from batch input."""
        device = next(self.model.parameters()).device

        # Here we perform ReaLchords generation.
        # Also remove BOS
        targets = batch["targets"][:, 1:].to(device)

        conditions = targets[:, 1::2]

        # Mask tokens after condition ends
        conditions_mask = conditions != self.pad_token_id

        # output_mask: True for unmasked tokens. Mask for masking out the
        #   output tokens, so that the model will not generate tokens after the
        #   condition ends.
        output_mask = torch.zeros(
            (conditions.shape[0], self.max_seq_len),
            dtype=torch.bool,
            device=device,
        )
        output_mask[:, 0::2][:, : conditions_mask.shape[1]] = conditions_mask
        output_mask[:, 1::2][:, : conditions_mask.shape[1]] = conditions_mask

        # generate_mask: True for unmasked tokens. Mask for marking which tokens
        #   are generated by the model.
        generate_mask = torch.zeros(
            (conditions.shape[0], self.max_seq_len),
            dtype=torch.bool,
            device=device,
        )
        generate_mask[:, 0::2][:, : conditions_mask.shape[1]] = conditions_mask

        gen_inputs = torch.full(
            (targets.shape[0], 1),
            self.bos_token_id,
            dtype=torch.long,
            device=device,
        )

        if enable_filter_fn:
            filter_logits_fn = self.filter_invalid_tokens_fn
        else:
            filter_logits_fn = self.default_filter_fn

        decoder_preds = self.model.generate_online(
            gen_inputs,
            conditions=conditions,
            seq_len=self.max_seq_len,
            cache_kv=True,
            eos_token=None,  # Do not check EOS token
            filter_logits_fn=filter_logits_fn,
        )
        decoder_preds.masked_fill_(~output_mask, self.pad_token_id)

        # In x-transformers, output will not contain prompt.
        # However, we need at least the BOS for calculating the log probs.
        # So here we add the prompt to the beginning of the sequences.
        input_len = 1
        sequences = torch.cat([gen_inputs, decoder_preds], dim=1)

        # Prepare action mask
        action_mask_seq = self.create_action_mask_from_sequences(
            sequences, input_len
        )
        action_mask = action_mask_seq & generate_mask

        attention_mask = torch.cat(
            [torch.ones_like(gen_inputs, dtype=torch.bool), output_mask], dim=1
        )

        return sequences, attention_mask, action_mask


class EncoderDecoderOfflineAnchor(ReaLchordsActor):
    """Encoder-decoder offline transformer used as anchor model for RL training.

    In this class, only forward method will be called.
    """

    def get_inputs_from_sequence(
        self, sequence: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        # remove bos
        sequence = sequence[:, 1:].clone()
        model_tokens = sequence[:, ::2]
        context_tokens = sequence[:, 1::2]

        # add eos to the first padding token
        model_tokens = add_eos_to_sequence(
            model_tokens, self.pad_token_id, self.eos_token_id
        )
        context_tokens = add_eos_to_sequence(
            context_tokens, self.pad_token_id, self.eos_token_id
        )

        # add bos to the beginning of the sequence
        model_tokens = add_bos_to_sequence(model_tokens, self.bos_token_id)
        context_tokens = add_bos_to_sequence(context_tokens, self.bos_token_id)

        model_mask = model_tokens != self.pad_token_id
        context_mask = context_tokens != self.pad_token_id
        return context_tokens, model_tokens, context_mask, model_mask

    def forward(
        self,
        sequences: torch.LongTensor,
        num_actions: Optional[Union[int, list[int]]] = None,
        attention_mask: Optional[torch.Tensor] = None,
        return_output=False,
        ring_attn_group: Optional[dist.ProcessGroup] = None,
        packed_seq_lens: Optional[list[int]] = None,
    ) -> torch.Tensor:
        """Returns action log probs from encoder-decoder offline model."""

        context_tokens, model_tokens, context_mask, model_mask = (
            self.get_inputs_from_sequence(sequences)
        )

        # In x-transformers, mask is True for unmasked tokens
        model_part_logits = self.model(
            context_tokens,
            model_tokens,
            enc_mask=context_mask,
            dec_mask=model_mask,
        )

        # remove the EOS token logits
        model_part_logits = model_part_logits[:, :-1, :]

        logits = torch.zeros(
            (sequences.size(0), sequences.size(1), self.model.dec_num_tokens),
            device=sequences.device,
        )

        logits[:, ::2, :] = model_part_logits

        if num_actions is None:
            assert return_output
            return logits

        log_probs = log_probs_from_logits(logits[:, :-1, :], sequences[:, 1:])

        action_log_probs = log_probs[:, -num_actions:]

        logits = logits[:, :-1, :]  # remove the last token logits

        if return_output:
            return (action_log_probs, logits)
        else:
            return action_log_probs


class DecoderDualPartActor(DecoderSingleAgentActor):
    """Decoder-only transformer generating with another model for RL training."""

    def init_filter_fn(self):
        counterpart_model_part = (
            "melody" if self.model_part == "chord" else "chord"
        )
        # self.filter_invalid_tokens_fn = partial(
        #     filter_invalid_tokens_generate_online,
        #     model_part=self.model_part,
        #     tokenizer=self.tokenizer,
        # )
        self.counterpart_filter_invalid_tokens_fn = partial(
            filter_invalid_tokens_generate_online,
            model_part=counterpart_model_part,
            tokenizer=self.tokenizer,
        )
        # self.default_filter_fn = partial(top_k, frac_num_tokens=1.0)
        # self.default_filter_fn = filter_special_token

        self.filter_invalid_tokens_fn = partial(top_k, frac_num_tokens=1.0)
        self.default_filter_fn = partial(top_k, frac_num_tokens=1.0)

    def get_mask_tailing_silence(self, sequences: torch.Tensor) -> torch.Tensor:
        """Mask the tailing silence in the sequences."""
        length = sequences.size(1)
        # Step 1: Check where x == V
        is_silence = sequences == self.silence_token_id  # [B, L]

        # Step 2: Reverse is_v to scan from end
        is_silence_rev = torch.flip(is_silence, dims=[1])  # [B, L]

        # Step 3: Identify trailing Vs using cumprod
        trailing_mask_rev = is_silence_rev.cumprod(dim=1)  # Still [B, L]

        # Step 4: Flip back
        trailing_mask = torch.flip(
            trailing_mask_rev, dims=[1]
        )  # [B, L], 1 where trailing V

        # Step 5: Find the first index where trailing_mask == 1 (start of tail)
        # Set to L if no trailing Vs
        start_indices = torch.where(
            trailing_mask.any(dim=1),
            trailing_mask.int().argmax(dim=1),
            torch.tensor(self.max_seq_len, device=sequences.device),
        )

        # Step 6: Create final mask
        mask = torch.arange(length, device=sequences.device).expand(
            sequences.size(0), length
        ) >= start_indices.unsqueeze(1)
        return mask

    def postprocess_sequences(
        self,
        gen_inputs: torch.Tensor,
        out_actor: torch.Tensor,
        device: torch.device,
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """Postprocess the sequences to mask the tailing silence."""

        model_part = out_actor[:, ::2]
        context_part = out_actor[:, 1::2]

        context_silence_mask = self.get_mask_tailing_silence(context_part)

        model_part = model_part.masked_fill(
            context_silence_mask, self.pad_token_id
        )
        context_part = context_part.masked_fill(
            context_silence_mask, self.pad_token_id
        )

        out_actor_postprocessed = torch.zeros_like(out_actor)
        out_actor_postprocessed[:, ::2] = model_part
        out_actor_postprocessed[:, 1::2] = context_part

        sequences = torch.cat([gen_inputs, out_actor_postprocessed], dim=1)

        attention_mask = sequences.ne(self.pad_token_id)
        action_mask = torch.zeros_like(
            sequences, dtype=torch.bool, device=device
        )
        # even positions are generated by actor
        action_mask[:, ::2] = 1

        action_mask = action_mask & attention_mask

        # remove the last token from action mask
        action_mask = action_mask[:, :-1]

        # filter out sequence if all of them are silence to avoid NaN in reward
        non_silence_idx = sequences[:, 1:].sum(-1) > 0
        sequences = sequences[non_silence_idx]
        attention_mask = attention_mask[non_silence_idx]
        action_mask = action_mask[non_silence_idx]

        return sequences, attention_mask, action_mask
